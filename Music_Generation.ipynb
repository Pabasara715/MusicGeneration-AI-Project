{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group No 36\n",
    "Music Generation Usig LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from typing import Dict, List, Optional, Sequence, Tuple\n",
    "import collections\n",
    "import datetime\n",
    "import glob\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import pretty_midi\n",
    "\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the required variables\n",
    "\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Sampling rate for audio playback\n",
    "_SAMPLING_RATE = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 1276\n"
     ]
    }
   ],
   "source": [
    "# Setting the path and loading the data\n",
    "\n",
    "data_dir = pathlib.Path('midifiles\\maestro-v3.0.0')\n",
    "\n",
    "filenames = glob.glob(str(data_dir/'**/*.mid*'))\n",
    "print('Number of files:', len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "midifiles\\maestro-v3.0.0\\2004\\MIDI-Unprocessed_SMF_02_R1_2004_01-05_ORIG_MID--AUDIO_02_R1_2004_06_Track06_wav.midi\n",
      "Number of instruments: 1\n",
      "Instrument name: Acoustic Grand Piano\n",
      "0: pitch=31, note_name=G1, duration=0.0656\n",
      "1: pitch=43, note_name=G2, duration=0.0792\n",
      "2: pitch=44, note_name=G#2, duration=0.0740\n",
      "3: pitch=32, note_name=G#1, duration=0.0729\n",
      "4: pitch=34, note_name=A#1, duration=0.0708\n",
      "5: pitch=46, note_name=A#2, duration=0.0948\n",
      "6: pitch=48, note_name=C3, duration=0.6260\n",
      "7: pitch=36, note_name=C2, duration=0.6542\n",
      "8: pitch=53, note_name=F3, duration=1.7667\n",
      "9: pitch=56, note_name=G#3, duration=1.7688\n"
     ]
    }
   ],
   "source": [
    "# analyzing and working with a sample file\n",
    "\n",
    "sample_file = filenames[1]\n",
    "print(sample_file)\n",
    "\n",
    "pm = pretty_midi.PrettyMIDI(sample_file)\n",
    "\n",
    "print('Number of instruments:', len(pm.instruments))\n",
    "instrument = pm.instruments[0]\n",
    "instrument_name = pretty_midi.program_to_instrument_name(instrument.program)\n",
    "print('Instrument name:', instrument_name)\n",
    "\n",
    "# Extracting the notes\n",
    "for i, note in enumerate(instrument.notes[:10]):\n",
    "    note_name = pretty_midi.note_number_to_name(note.pitch)\n",
    "    duration = note.end - note.start\n",
    "    print(f'{i}: pitch={note.pitch}, note_name={note_name}, duration={duration:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pitch</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>step</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>1.032292</td>\n",
       "      <td>1.111458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>1.040625</td>\n",
       "      <td>1.106250</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.065625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>1.142708</td>\n",
       "      <td>1.216667</td>\n",
       "      <td>0.102083</td>\n",
       "      <td>0.073958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>1.144792</td>\n",
       "      <td>1.217708</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.072917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>1.208333</td>\n",
       "      <td>1.303125</td>\n",
       "      <td>0.063542</td>\n",
       "      <td>0.094792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pitch     start       end      step  duration\n",
       "0     43  1.032292  1.111458  0.000000  0.079167\n",
       "1     31  1.040625  1.106250  0.008333  0.065625\n",
       "2     44  1.142708  1.216667  0.102083  0.073958\n",
       "3     32  1.144792  1.217708  0.002083  0.072917\n",
       "4     46  1.208333  1.303125  0.063542  0.094792"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting the notes from the sample MIDI file\n",
    "\n",
    "def midi_to_notes(midi_file: str) -> pd.DataFrame:\n",
    "    pm = pretty_midi.PrettyMIDI(midi_file)\n",
    "    instrument = pm.instruments[0]\n",
    "    notes = collections.defaultdict(list)\n",
    "\n",
    "    # Sort the notes by start time\n",
    "    sorted_notes = sorted(instrument.notes, key=lambda note: note.start)\n",
    "    prev_start = sorted_notes[0].start\n",
    "\n",
    "    for note in sorted_notes:\n",
    "        start = note.start\n",
    "        end = note.end\n",
    "        notes['pitch'].append(note.pitch)\n",
    "        notes['start'].append(start)\n",
    "        notes['end'].append(end)\n",
    "        notes['step'].append(start - prev_start)\n",
    "        notes['duration'].append(end - start)\n",
    "        prev_start = start\n",
    "\n",
    "    return pd.DataFrame({name: np.array(value) for name, value in notes.items()})\n",
    "\n",
    "raw_notes = midi_to_notes(sample_file)\n",
    "raw_notes.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['G2' 'G1' 'G#2' 'G#1' 'A#2' 'A#1' 'C3' 'C2' 'F3' 'D4']\n"
     ]
    }
   ],
   "source": [
    "# Converting to note names by considering the respective pitch values\n",
    "\n",
    "get_note_names = np.vectorize(pretty_midi.note_number_to_name)\n",
    "sample_note_names = get_note_names(raw_notes['pitch'])\n",
    "print(sample_note_names[:10])\n",
    "\n",
    "# Visualizing the paramaters of the muscial notes of the piano\n",
    "\n",
    "def plot_piano_roll(notes: pd.DataFrame, count: Optional[int] = None):\n",
    "    if count:\n",
    "        title = f'First {count} notes'\n",
    "    else:\n",
    "        title = f'Whole track'\n",
    "        count = len(notes['pitch'])\n",
    "        \n",
    "        plt.figure(figsize=(20, 4))\n",
    "        plot_pitch = np.stack([notes['pitch'], notes['pitch']], axis=0)\n",
    "        plot_start_stop = np.stack([notes['start'], notes['end']], axis=0)\n",
    "        \n",
    "        plt.plot(plot_start_stop[:, :count], plot_pitch[:, :count], color=\"b\", marker=\".\")\n",
    "        plt.xlabel('Time [s]')\n",
    "        plt.ylabel('Pitch')\n",
    "        _ = plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def notes_to_midi(notes: pd.DataFrame, out_file: str, instrument_name: str,\n",
    "                  velocity: int = 100) -> pretty_midi.PrettyMIDI:\n",
    "\n",
    "    pm = pretty_midi.PrettyMIDI()\n",
    "    instrument = pretty_midi.Instrument(\n",
    "      program=pretty_midi.instrument_name_to_program(\n",
    "          instrument_name))\n",
    "\n",
    "    prev_start = 0\n",
    "    for i, note in notes.iterrows():\n",
    "        start = float(prev_start + note['step'])\n",
    "        end = float(start + note['duration'])\n",
    "        \n",
    "        note = pretty_midi.Note(velocity=velocity, pitch=int(note['pitch']),\n",
    "                                start=start, end=end)\n",
    "        instrument.notes.append(note)\n",
    "        prev_start = start\n",
    "\n",
    "    pm.instruments.append(instrument)\n",
    "    pm.write(out_file)\n",
    "    return pm\n",
    "\n",
    "example_file = 'example.midi'\n",
    "example_pm = notes_to_midi(\n",
    "    raw_notes, out_file=example_file, instrument_name=instrument_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_files = 5\n",
    "all_notes = []\n",
    "for f in filenames[:num_files]:\n",
    "    notes = midi_to_notes(f)\n",
    "    all_notes.append(notes)\n",
    "\n",
    "all_notes = pd.concat(all_notes)\n",
    "\n",
    "n_notes = len(all_notes)\n",
    "print('Number of notes parsed:', n_notes)\n",
    "\n",
    "key_order = ['pitch', 'step', 'duration']\n",
    "train_notes = np.stack([all_notes[key] for key in key_order], axis=1)\n",
    "\n",
    "notes_ds = tf.data.Dataset.from_tensor_slices(train_notes)\n",
    "notes_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(dataset: tf.data.Dataset, seq_length: int,\n",
    "                     vocab_size = 128) -> tf.data.Dataset:\n",
    "    \"\"\"Returns TF Dataset of sequence and label examples.\"\"\"\n",
    "    seq_length = seq_length+1\n",
    "\n",
    "    # Take 1 extra for the labels\n",
    "    windows = dataset.window(seq_length, shift=1, stride=1,\n",
    "                              drop_remainder=True)\n",
    "\n",
    "    # `flat_map` flattens the\" dataset of datasets\" into a dataset of tensors\n",
    "    flatten = lambda x: x.batch(seq_length, drop_remainder=True)\n",
    "    sequences = windows.flat_map(flatten)\n",
    "\n",
    "    # Normalize note pitch\n",
    "    def scale_pitch(x):\n",
    "        x = x/[vocab_size,1.0,1.0]\n",
    "        return x\n",
    "\n",
    "    # Split the labels\n",
    "    def split_labels(sequences):\n",
    "        inputs = sequences[:-1]\n",
    "        labels_dense = sequences[-1]\n",
    "        labels = {key:labels_dense[i] for i,key in enumerate(key_order)}\n",
    "\n",
    "        return scale_pitch(inputs), labels\n",
    "\n",
    "    return sequences.map(split_labels, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "seq_length = 25\n",
    "vocab_size = 128\n",
    "seq_ds = create_sequences(notes_ds, seq_length, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "buffer_size = n_notes - seq_length  # the number of items in the dataset\n",
    "train_ds = (seq_ds\n",
    "            .shuffle(buffer_size)\n",
    "            .batch(batch_size, drop_remainder=True)\n",
    "            .cache()\n",
    "            .prefetch(tf.data.experimental.AUTOTUNE))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
